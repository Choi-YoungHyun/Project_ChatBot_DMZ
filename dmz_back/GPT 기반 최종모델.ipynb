{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOog/ytOJMxCH6ep69AA3Nr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8KA7Zu1GckR","executionInfo":{"status":"ok","timestamp":1691021440190,"user_tz":-540,"elapsed":8727,"user":{"displayName":"송태인","userId":"07841994113003459229"}},"outputId":"a3fcd9e7-b336-44d9-97b8-69f433eb5920"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m952.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n","Installing collected packages: openai\n","Successfully installed openai-0.27.8\n"]}]},{"cell_type":"code","source":["# 설치 모듈\n","!pip install transformers\n","!pip install datasets\n","!pip install accelerate\n","!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtWfPxwGaQUR","executionInfo":{"status":"ok","timestamp":1691021494480,"user_tz":-540,"elapsed":54293,"user":{"displayName":"송태인","userId":"07841994113003459229"}},"outputId":"d3741f12-0d99-48b7-f517-c54359549ffe"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n","Collecting datasets\n","  Downloading datasets-2.14.2-py3-none-any.whl (518 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.2 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Collecting accelerate\n","  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.21.0\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"]}]},{"cell_type":"code","execution_count":12,"metadata":{"id":"f2WI7TYtGWWn","executionInfo":{"status":"ok","timestamp":1691021944460,"user_tz":-540,"elapsed":550,"user":{"displayName":"송태인","userId":"07841994113003459229"}}},"outputs":[],"source":["import os\n","import openai\n","openai.organization = \"org-t59W5OwxkINFi0IhzgLvTQ8e\"\n","openai.api_key = \"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\""]},{"cell_type":"code","source":["response = openai.ChatCompletion.create(\n","    model=\"gpt-3.5-turbo\",\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": \" '요즘잘자쿨냥이' 가 뭐야?\",\n","        },\n","    ]\n",")\n","bot_response = response['choices'][0]['message']['content']\n","print(bot_response)"],"metadata":{"id":"7UWiIiP_GZ5f","executionInfo":{"status":"ok","timestamp":1691021951004,"user_tz":-540,"elapsed":6546,"user":{"displayName":"송태인","userId":"07841994113003459229"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4c21a88-248d-4677-fa0e-2fe69cbdb537"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["'요즘잘자쿨냥이'는 일상 생활에서 스트레스를 푸는 방법이나 휴식을 취하는 방법과 관련된 내용들을 공유하는 인터넷 커뮤니티 혹은 소셜 미디어 계정을 말합니다. '잘 자는 쿨한 고양이'를 상징적으로 사용하여, 현대 사회에서 긴장과 스트레스로 인해 힘들어하는 사람들을 위로하고 편안한 분위기를 제공하려는 의도로 만들어진 것입니다. 이러한 커뮤니티나 계정에서는 잠자는 고양이 사진이나 동영상, 힐링 테마의 글 등이 많이 공유됩니다.\n"]}]},{"cell_type":"code","source":["# 데이터 가져오기\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","\n","df = pd.read_csv('/content/drive/MyDrive/KDT/프로젝트2/DB/신조어DB_0802 최종.csv' , encoding='cp949')\n","\n","df.columns = ['신조어', '해석', '유사어']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuNsEA36aib_","executionInfo":{"status":"ok","timestamp":1691021516096,"user_tz":-540,"elapsed":21624,"user":{"displayName":"송태인","userId":"07841994113003459229"}},"outputId":"47eb0b1e-7b4c-4396-cb56-eb54f62b48d4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# improve_sentence 미적용\n","# 재해석 문제 해결\n","# 다수의 해석이 있는 경우 해결\n","# GPT 버젼\n","\n","import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import torch\n","\n","def get_word_replacements_from_dataframe(df):\n","    word_replacements = {}\n","    for index, row in df.iterrows():\n","        word = row['신조어']\n","        meanings = [row['해석']]\n","        synonyms = row['유사어'].split(',')\n","        synonyms = [synonym.strip() for synonym in synonyms]  # 띄어쓰기 제거\n","        word_replacements[word] = meanings + synonyms\n","    return word_replacements\n","\n","def check_word_in_sentence(sentence, word_list):\n","    found_words = []\n","    for word in word_list:\n","        if word in sentence:\n","            found_words.append(word)  # 캐치한 신조어를 리스트에 추가\n","    return found_words\n","\n","\n","def replace_words(sentence, word_replacements):\n","    sentences = [sentence]\n","    already_replaced = set()\n","\n","    for word, replacements in word_replacements.items():\n","        if word in already_replaced:\n","            continue\n","\n","        new_sentences = []\n","        for sent in sentences:\n","            if word in sent:\n","                for replacement in replacements[1:]:\n","                    new_sentence = sent.replace(word, replacement)\n","                    new_sentences.append(new_sentence)\n","                    already_replaced.add(replacement)\n","\n","                    # 만약 새로운 대체어가 다시 신조어를 포함하고 있다면, 해당 신조어도 추가\n","                    for replaced_word, replaced_replacements in word_replacements.items():\n","                        if replaced_word != word and replaced_word in replacement:\n","                            already_replaced.add(replaced_word)\n","            else:\n","                new_sentences.append(sent)\n","        sentences = new_sentences\n","\n","    return sentences\n","\n","\n","\n","def evaluate_naturalness(sentence_list):\n","    tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n","    model = BertForSequenceClassification.from_pretrained('klue/bert-base')\n","\n","    max_naturalness_score = -1\n","    most_natural_sentence = None\n","\n","    for i in range(len(sentence_list)):\n","        for j in range(i+1, len(sentence_list)):\n","            sentence1 = sentence_list[i]\n","            sentence2 = sentence_list[j]\n","\n","            inputs = tokenizer(sentence1, sentence2, add_special_tokens=True, return_tensors='pt', truncation=True, padding=True)\n","\n","            with torch.no_grad():\n","                outputs = model(**inputs)\n","\n","            logits = outputs.logits\n","            prob = torch.softmax(logits, dim=1)\n","            similarity_score = prob[:, 1].item()\n","\n","            if similarity_score > max_naturalness_score:\n","                max_naturalness_score = similarity_score\n","                most_natural_sentence = sentence1 if similarity_score > 0.5 else sentence2\n","\n","    return most_natural_sentence\n","\n","def improve_sentence(sentence):\n","    response = openai.ChatCompletion.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[\n","            {\n","                \"role\": \"user\",\n","                \"content\": f\"{sentence} 를 자연스러운 문장으로 바꿔줘\",\n","            },\n","        ]\n","    )\n","\n","    bot_response = response['choices'][0]['message']['content']\n","    return bot_response\n","\n","def main():\n","    word_replacements = get_word_replacements_from_dataframe(df)\n","\n","    while True:\n","        user_input = input(\"문장을 입력하세요 (종료하려면 '끝' 입력): \")\n","        if user_input.lower() == '끝':\n","            break\n","\n","        found_words = check_word_in_sentence(user_input, word_replacements.keys())\n","        if found_words:\n","            print(f\"신조어: {', '.join(found_words)}\")\n","            replaced_sentences = replace_words(user_input, word_replacements)\n","            for i, sentence in enumerate(replaced_sentences, 1):\n","                print(f\"{i}. 번역 결과: {sentence}\")\n","\n","            if len(replaced_sentences) > 1:\n","                most_natural_sentence = evaluate_naturalness(replaced_sentences)\n","                print(f\"가장 자연스러운 문장: {most_natural_sentence}\")\n","                bot_response = improve_sentence(most_natural_sentence)\n","                print(f\"GPT 변환문장: {bot_response}\")\n","                super_most_natural_sentence = evaluate_naturalness((most_natural_sentence,bot_response))\n","                print(f\"GPT VS 가장 자연스러운 문장:{super_most_natural_sentence}\")\n","            else:\n","                bot_response = improve_sentence(replaced_sentences[0])\n","                print(f\"GPT 변환문장: {bot_response}\")\n","                super_most_natural_sentence = evaluate_naturalness((replaced_sentences[0], bot_response))\n","                print(f\"GPT VS 가장 자연스러운 문장:{super_most_natural_sentence}\")\n","\n","\n","            for idx, found_word in enumerate(found_words, 1):\n","                print(f\"해석 {idx}. {found_word} : {word_replacements[found_word][0]}\")  # 해당 신조어의 해석 출력\n","        else:\n","            print(\"입력한 문장에 설정된 단어가 포함되어 있지 않습니다.\")\n","\n","\n","\n","        print(\"==============================================\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZc2VWcSHYSv","executionInfo":{"status":"ok","timestamp":1691022571983,"user_tz":-540,"elapsed":38495,"user":{"displayName":"송태인","userId":"07841994113003459229"}},"outputId":"51654653-d1c1-4bec-a184-b8695d7077e1"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["문장을 입력하세요 (종료하려면 '끝' 입력): 서승수식 인종청소론 킹받네\n","신조어: 킹받네\n","1. 번역 결과: 서승수식 인종청소론 열받네\n","GPT 변환문장: 서승수식으로 표현된 인종 청소론에 화가 나네요.\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["GPT VS 가장 자연스러운 문장:서승수식 인종청소론 열받네\n","해석 1. 킹받네 : 열받네이라는 뜻입니다\n","==============================================\n","문장을 입력하세요 (종료하려면 '끝' 입력): 끝\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2PPQ3AEwaFur","executionInfo":{"status":"aborted","timestamp":1691021598600,"user_tz":-540,"elapsed":2,"user":{"displayName":"송태인","userId":"07841994113003459229"}}},"execution_count":null,"outputs":[]}]}